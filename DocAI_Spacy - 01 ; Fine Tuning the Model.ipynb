{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026d118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5d49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6dea76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data from the CSV file\n",
    "data = pd.read_csv(r\"D:\\Downloads\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "713aea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Telephone Number             Name House Number    Society Name  \\\n",
      "0         9876543210     Ananya Gupta         12/A  ABC Apartments   \n",
      "1         9876543211     Rahul Sharma         34/B      XYZ Towers   \n",
      "2         9876543212      Priya Singh         56/C   PQR Residency   \n",
      "3         9876543213       Amit Patel         78/D     MNO Estates   \n",
      "4         9876543214     Kavita Mehta         90/E     LMN Enclave   \n",
      "5         9876543215     Rajesh Kumar         12/F     GHI Heights   \n",
      "6         9876543216      Pooja Verma         34/G     JKL Complex   \n",
      "7         9876543217     Deepak Singh         56/H     DEF Society   \n",
      "8         9876543218    Shalini Gupta         78/I     MNP Gardens   \n",
      "9         9876543219     Rohit Sharma         90/J   RST Residency   \n",
      "10        9876543220     Akshay Verma         12/K      UVW Towers   \n",
      "11        9876543221      Megha Patel         34/L     QWE Enclave   \n",
      "12        9876543222      Vivek Singh         56/M  ASD Apartments   \n",
      "13        9876543223    Anjali Kapoor         78/N     ZXC Heights   \n",
      "14        9876543224      Aman Sharma         90/O     POI Society   \n",
      "15        9876543225      Ritu Saxena         12/P   KLJ Residency   \n",
      "16        9876543226    Sandeep Mehta         34/Q      QWE Towers   \n",
      "17        9876543227      Divya Gupta         56/R     JKL Society   \n",
      "18        9876543228     Rajat Khanna         78/S     ASD Enclave   \n",
      "19        9876543229      Ayesha Khan         90/T     ZXC Gardens   \n",
      "20        9876543230    Saurabh Singh         12/U   POI Residency   \n",
      "21        9876543231    Kritika Verma         34/V     UVW Complex   \n",
      "22        9876543232    Vikram Kapoor         56/W     RST Heights   \n",
      "23        9876543233   Anushka Saxena         78/X      ASD Towers   \n",
      "24        9876543234      Manoj Gupta         90/Y     JKL Gardens   \n",
      "25        9876543235  Priyanka Sharma         12/Z   QWE Residency   \n",
      "26        9876543236  Siddharth Singh        34/AA     KLJ Heights   \n",
      "27        9876543239    Arushi Kapoor        90/DD     POI Enclave   \n",
      "28        9876543240   Deepika Saxena        12/EE     UVW Gardens   \n",
      "29        9876543241      Ankit Gupta        34/FF     RST Society   \n",
      "30        9876543243     Swati Khanna        78/HH   ASD Residency   \n",
      "31        9876543244    Saurabh Verma        90/II     ZXC Heights   \n",
      "32        9876543245     Rajesh Mehta        12/JJ      POI Towers   \n",
      "33        9971025644   Himanshi Verma          290   Seemant Vihar   \n",
      "\n",
      "             City  Pin Code           State Country  \n",
      "0       New Delhi    110001           Delhi   India  \n",
      "1          Mumbai    400001     Maharashtra   India  \n",
      "2         Kolkata    700001     West Bengal   India  \n",
      "3       Ahmedabad    380001         Gujarat   India  \n",
      "4         Chennai    600001      Tamil Nadu   India  \n",
      "5       Bengaluru    560001       Karnataka   India  \n",
      "6       Hyderabad    500001       Telangana   India  \n",
      "7          Jaipur    302001       Rajasthan   India  \n",
      "8            Pune    411001     Maharashtra   India  \n",
      "9         Lucknow    226001   Uttar Pradesh   India  \n",
      "10     Chandigarh    160001          Punjab   India  \n",
      "11         Bhopal    462001  Madhya Pradesh   India  \n",
      "12          Patna    800001           Bihar   India  \n",
      "13         Ranchi    834001       Jharkhand   India  \n",
      "14        Gurgaon    122001         Haryana   India  \n",
      "15      Faridabad    121001         Haryana   India  \n",
      "16         Nagpur    440001     Maharashtra   India  \n",
      "17         Indore    452001  Madhya Pradesh   India  \n",
      "18         Kanpur    208001   Uttar Pradesh   India  \n",
      "19       Ludhiana    141001          Punjab   India  \n",
      "20       Varanasi    221001   Uttar Pradesh   India  \n",
      "21       Amritsar    143001          Punjab   India  \n",
      "22       Jabalpur    482001  Madhya Pradesh   India  \n",
      "23  Visakhapatnam    530001  Andhra Pradesh   India  \n",
      "24        Cuttack    753001          Odisha   India  \n",
      "25    Bhubaneswar    751001          Odisha   India  \n",
      "26         Raipur    492001    Chhattisgarh   India  \n",
      "27       Shillong    793001       Meghalaya   India  \n",
      "28       Dehradun    248001     Uttarakhand   India  \n",
      "29        Gangtok    737101          Sikkim   India  \n",
      "30         Raipur    492001    Chhattisgarh   India  \n",
      "31         Imphal    795001         Manipur   India  \n",
      "32         Kohima    797001        Nagaland   India  \n",
      "33      Hyderabad    501010       Telangana   India  \n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292dd0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Telephone Number', 'Name', 'House Number', 'Society Name', 'City',\n",
       "       'Pin Code', 'State', 'Country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04bc1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Entity       Value\n",
      "0    Telephone Number  9876543210\n",
      "1    Telephone Number  9876543211\n",
      "2    Telephone Number  9876543212\n",
      "3    Telephone Number  9876543213\n",
      "4    Telephone Number  9876543214\n",
      "..                ...         ...\n",
      "267           Country       India\n",
      "268           Country       India\n",
      "269           Country       India\n",
      "270           Country       India\n",
      "271           Country       India\n",
      "\n",
      "[272 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering\n",
    "# Melt the DataFrame to convert columns to rows\n",
    "melted_data = pd.melt(data, var_name='Entity', value_name='Value')\n",
    " \n",
    "# 'Entity' column now contains the labels for the entities (former column names)\n",
    "# 'Value' column contains the corresponding values\n",
    " \n",
    "print(melted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92171a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels for each column\n",
    "labels = ['Telephone Number', 'Name', 'House Number', 'Society Name', 'City', 'Pin Code', 'State', 'Country']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c307aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Telephone Number', 'Name', 'House Number', 'Society Name', 'City',\n",
       "       'Pin Code', 'State', 'Country'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_data['Entity'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33a18515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Telephone Number\n",
      "Training set size: 23\n",
      "Testing set size: 5\n",
      "Validation set size: 6\n",
      "===================\n",
      "Entity: Name\n",
      "Training set size: 23\n",
      "Testing set size: 5\n",
      "Validation set size: 6\n",
      "===================\n",
      "Entity: House Number\n",
      "Training set size: 23\n",
      "Testing set size: 5\n",
      "Validation set size: 6\n",
      "===================\n",
      "Entity: Society Name\n",
      "Training set size: 23\n",
      "Testing set size: 5\n",
      "Validation set size: 6\n",
      "===================\n",
      "Entity: City\n",
      "Training set size: 23\n",
      "Testing set size: 5\n",
      "Validation set size: 6\n",
      "===================\n",
      "Entity: Pin Code\n",
      "Training set size: 23\n",
      "Testing set size: 5\n",
      "Validation set size: 6\n",
      "===================\n",
      "Entity: State\n",
      "Training set size: 23\n",
      "Testing set size: 5\n",
      "Validation set size: 6\n",
      "===================\n",
      "Entity: Country\n",
      "Training set size: 23\n",
      "Testing set size: 5\n",
      "Validation set size: 6\n",
      "===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\purus\\AppData\\Local\\Temp\\ipykernel_24456\\1330704523.py:11: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_train_final = pd.Series()\n",
      "C:\\Users\\purus\\AppData\\Local\\Temp\\ipykernel_24456\\1330704523.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_test_final = pd.Series()\n",
      "C:\\Users\\purus\\AppData\\Local\\Temp\\ipykernel_24456\\1330704523.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  y_val_final = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your melted data is stored in a DataFrame called 'melted_data'\n",
    "# and the labels are in a column named 'Value'\n",
    "\n",
    "entity_lists = melted_data['Entity'].unique()\n",
    "X_test_final = pd.DataFrame()\n",
    "X_train_final = pd.DataFrame()\n",
    "X_val_final = pd.DataFrame()\n",
    "y_train_final = pd.Series()\n",
    "y_test_final = pd.Series()\n",
    "y_val_final = pd.Series()\n",
    "\n",
    "for entity in entity_lists:\n",
    "    # Filter data for the current entity\n",
    "    entity_data = melted_data[melted_data['Entity'] == entity]\n",
    "    \n",
    "    # Split into features and labels\n",
    "   # X = entity_data.drop('Value', axis=1)  # Assuming 'Value' is the label column\n",
    "    X = entity_data['Value']\n",
    "    y = entity_data['Entity']\n",
    "    \n",
    "    # Split into train, test, and validation sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Append the splits to the final DataFrames and Series\n",
    "    X_train_final = pd.concat([X_train_final, X_train], ignore_index=True)\n",
    "    X_test_final = pd.concat([X_test_final, X_test], ignore_index=True)\n",
    "    X_val_final = pd.concat([X_val_final, X_val], ignore_index=True)\n",
    "    \n",
    "    y_train_final = pd.concat([y_train_final, y_train], ignore_index=True)\n",
    "    y_test_final = pd.concat([y_test_final, y_test], ignore_index=True)\n",
    "    y_val_final = pd.concat([y_val_final, y_val], ignore_index=True)\n",
    "\n",
    "    # Display the sizes of the splits for the current entity\n",
    "    print(f\"Entity: {entity}\")\n",
    "    print(\"Training set size:\", len(X_train))\n",
    "    print(\"Testing set size:\", len(X_test))\n",
    "    print(\"Validation set size:\", len(X_val))\n",
    "    print(\"===================\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "528b7f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_final                   0\n",
      "0        9876543245\n",
      "1        9876543218\n",
      "2        9876543222\n",
      "3        9876543236\n",
      "4        9876543231\n",
      "5      Rajesh Mehta\n",
      "6     Shalini Gupta\n",
      "7       Vivek Singh\n",
      "8   Siddharth Singh\n",
      "9     Kritika Verma\n",
      "10            12/JJ\n",
      "11             78/I\n",
      "12             56/M\n",
      "13            34/AA\n",
      "14             34/V\n",
      "15       POI Towers\n",
      "16      MNP Gardens\n",
      "17   ASD Apartments\n",
      "18      KLJ Heights\n",
      "19      UVW Complex\n",
      "20           Kohima\n",
      "21             Pune\n",
      "22            Patna\n",
      "23           Raipur\n",
      "24         Amritsar\n",
      "25           797001\n",
      "26           411001\n",
      "27           800001\n",
      "28           492001\n",
      "29           143001\n",
      "30         Nagaland\n",
      "31      Maharashtra\n",
      "32            Bihar\n",
      "33     Chhattisgarh\n",
      "34           Punjab\n",
      "35            India\n",
      "36            India\n",
      "37            India\n",
      "38            India\n",
      "39            India\n",
      "X_train_final               0\n",
      "0    9876543214\n",
      "1    9876543226\n",
      "2    9876543227\n",
      "3    9876543215\n",
      "4    9876543223\n",
      "..          ...\n",
      "179       India\n",
      "180       India\n",
      "181       India\n",
      "182       India\n",
      "183       India\n",
      "\n",
      "[184 rows x 1 columns]\n",
      "X_val_final                  0\n",
      "0       9876543234\n",
      "1       9876543225\n",
      "2       9876543219\n",
      "3       9876543210\n",
      "4       9876543239\n",
      "5       9876543229\n",
      "6      Manoj Gupta\n",
      "7      Ritu Saxena\n",
      "8     Rohit Sharma\n",
      "9     Ananya Gupta\n",
      "10   Arushi Kapoor\n",
      "11     Ayesha Khan\n",
      "12            90/Y\n",
      "13            12/P\n",
      "14            90/J\n",
      "15            12/A\n",
      "16           90/DD\n",
      "17            90/T\n",
      "18     JKL Gardens\n",
      "19   KLJ Residency\n",
      "20   RST Residency\n",
      "21  ABC Apartments\n",
      "22     POI Enclave\n",
      "23     ZXC Gardens\n",
      "24         Cuttack\n",
      "25       Faridabad\n",
      "26         Lucknow\n",
      "27       New Delhi\n",
      "28        Shillong\n",
      "29        Ludhiana\n",
      "30          753001\n",
      "31          121001\n",
      "32          226001\n",
      "33          110001\n",
      "34          793001\n",
      "35          141001\n",
      "36          Odisha\n",
      "37         Haryana\n",
      "38   Uttar Pradesh\n",
      "39           Delhi\n",
      "40       Meghalaya\n",
      "41          Punjab\n",
      "42           India\n",
      "43           India\n",
      "44           India\n",
      "45           India\n",
      "46           India\n",
      "47           India\n",
      "y_train_final 0      Telephone Number\n",
      "1      Telephone Number\n",
      "2      Telephone Number\n",
      "3      Telephone Number\n",
      "4      Telephone Number\n",
      "             ...       \n",
      "179             Country\n",
      "180             Country\n",
      "181             Country\n",
      "182             Country\n",
      "183             Country\n",
      "Length: 184, dtype: object\n",
      "y_test_final 0     Telephone Number\n",
      "1     Telephone Number\n",
      "2     Telephone Number\n",
      "3     Telephone Number\n",
      "4     Telephone Number\n",
      "5                 Name\n",
      "6                 Name\n",
      "7                 Name\n",
      "8                 Name\n",
      "9                 Name\n",
      "10        House Number\n",
      "11        House Number\n",
      "12        House Number\n",
      "13        House Number\n",
      "14        House Number\n",
      "15        Society Name\n",
      "16        Society Name\n",
      "17        Society Name\n",
      "18        Society Name\n",
      "19        Society Name\n",
      "20                City\n",
      "21                City\n",
      "22                City\n",
      "23                City\n",
      "24                City\n",
      "25            Pin Code\n",
      "26            Pin Code\n",
      "27            Pin Code\n",
      "28            Pin Code\n",
      "29            Pin Code\n",
      "30               State\n",
      "31               State\n",
      "32               State\n",
      "33               State\n",
      "34               State\n",
      "35             Country\n",
      "36             Country\n",
      "37             Country\n",
      "38             Country\n",
      "39             Country\n",
      "dtype: object\n",
      "y_val_final 0     Telephone Number\n",
      "1     Telephone Number\n",
      "2     Telephone Number\n",
      "3     Telephone Number\n",
      "4     Telephone Number\n",
      "5     Telephone Number\n",
      "6                 Name\n",
      "7                 Name\n",
      "8                 Name\n",
      "9                 Name\n",
      "10                Name\n",
      "11                Name\n",
      "12        House Number\n",
      "13        House Number\n",
      "14        House Number\n",
      "15        House Number\n",
      "16        House Number\n",
      "17        House Number\n",
      "18        Society Name\n",
      "19        Society Name\n",
      "20        Society Name\n",
      "21        Society Name\n",
      "22        Society Name\n",
      "23        Society Name\n",
      "24                City\n",
      "25                City\n",
      "26                City\n",
      "27                City\n",
      "28                City\n",
      "29                City\n",
      "30            Pin Code\n",
      "31            Pin Code\n",
      "32            Pin Code\n",
      "33            Pin Code\n",
      "34            Pin Code\n",
      "35            Pin Code\n",
      "36               State\n",
      "37               State\n",
      "38               State\n",
      "39               State\n",
      "40               State\n",
      "41               State\n",
      "42             Country\n",
      "43             Country\n",
      "44             Country\n",
      "45             Country\n",
      "46             Country\n",
      "47             Country\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test_final\", X_test_final)\n",
    "print(\"X_train_final\", X_train_final)\n",
    "print(\"X_val_final\", X_val_final)\n",
    "print(\"y_train_final\", y_train_final)\n",
    "print(\"y_test_final\", y_test_final)\n",
    "print(\"y_val_final\", y_val_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a8a8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_final 40\n",
      "X_train_final 184\n",
      "X_val_final 48\n",
      "y_train_final 184\n",
      "y_test_final 40\n",
      "y_val_final 48\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test_final\", len(X_test_final))\n",
    "print(\"X_train_final\", len(X_train_final))\n",
    "print(\"X_val_final\", len(X_val_final))\n",
    "print(\"y_train_final\", len(y_train_final))\n",
    "print(\"y_test_final\", len(y_test_final))\n",
    "print(\"y_val_final\", len(y_val_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a049637b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9876543214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9876543226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9876543227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9876543215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9876543223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  9876543214\n",
       "1  9876543226\n",
       "2  9876543227\n",
       "3  9876543215\n",
       "4  9876543223"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5231b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train the model\n",
    "def train_custom_ner_model(X_train, X_test, y_train, y_test, labels, iterations=100, model_output_dir=None):\n",
    "    nlp = spacy.blank('en')  # Initialize blank English model\n",
    "\n",
    "    # Add NER component to the pipeline\n",
    "    ner = nlp.add_pipe('ner', last=True)\n",
    "\n",
    "    # Add labels for your entities\n",
    "    for label in labels:\n",
    "        ner.add_label(label)\n",
    "\n",
    "    # Disable other pipeline components during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            losses = {}\n",
    "            for i in range(len(X_train)):\n",
    "                # Convert Series to string\n",
    "                text = str(X_train.iloc[i].item()) if isinstance(X_train.iloc[i], pd.Series) else str(X_train.iloc[i])\n",
    "                \n",
    "                # Convert annotations to a list of tuples or handle if it's an integer or string\n",
    "                annotations = y_train.iloc[i]\n",
    "                if isinstance(annotations, (int, str)):\n",
    "                    annotations = [(0, len(text), str(annotations))]  # Replace with appropriate start, end, label\n",
    "                else:\n",
    "                    annotations = annotations.tolist()\n",
    "\n",
    "                example = Example.from_dict(nlp.make_doc(text), {\"entities\": annotations})\n",
    "                nlp.update([example], drop=0.5, losses=losses)\n",
    "\n",
    "            # Calculate accuracy on the test data\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "            for i in range(len(X_test)):\n",
    "                # Convert Series to string\n",
    "                text = str(X_test.iloc[i].item()) if isinstance(X_test.iloc[i], pd.Series) else str(X_test.iloc[i])\n",
    "                \n",
    "                # Convert annotations to a list of tuples or handle if it's an integer or string\n",
    "                annotations = y_test.iloc[i]\n",
    "                if isinstance(annotations, (int, str)):\n",
    "                    annotations = [(0, len(text), str(annotations))]  # Replace with appropriate start, end, label\n",
    "                else:\n",
    "                    annotations = annotations.tolist()\n",
    "\n",
    "                doc = nlp(text)\n",
    "                true_entities = set([(start, end, label) for start, end, label in annotations])\n",
    "                predicted_entities = set([(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents])\n",
    "\n",
    "                correct_predictions += len(true_entities.intersection(predicted_entities))\n",
    "                total_predictions += len(predicted_entities)\n",
    "\n",
    "            accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "            print(f\"Iteration {itn + 1}/{iterations}: Loss = {losses.get('ner', 0):.4f}, Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "    # Save the model to the specified output directory\n",
    "    if model_output_dir:\n",
    "        nlp.to_disk(model_output_dir)\n",
    "        print(f\"Model saved to: {model_output_dir}\")\n",
    "\n",
    "    return nlp\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have X_train_final, X_test_final, y_train_final, y_test_final\n",
    "# Split your data into training and testing sets\n",
    "# labels = ['LABEL1', 'LABEL2', ...]  # Replace with your actual labels\n",
    "# train_custom_ner_model(X_train_final, X_test_final, y_train_final, y_test_final, labels, iterations=100, model_output_dir='path/to/save/model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce6dbeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\purus\\\\Downloads'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d32ffcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_dir = os.getcwd() #save the model in current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e696a7b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100: Loss = 258.4811, Accuracy = 0.0847\n",
      "Iteration 2/100: Loss = 246.5997, Accuracy = 0.1961\n",
      "Iteration 3/100: Loss = 238.5832, Accuracy = 0.1064\n",
      "Iteration 4/100: Loss = 223.3734, Accuracy = 0.4255\n",
      "Iteration 5/100: Loss = 168.9934, Accuracy = 0.7250\n",
      "Iteration 6/100: Loss = 115.4287, Accuracy = 0.7250\n",
      "Iteration 7/100: Loss = 113.9445, Accuracy = 0.7250\n",
      "Iteration 8/100: Loss = 98.5096, Accuracy = 0.6750\n",
      "Iteration 9/100: Loss = 114.7425, Accuracy = 0.7436\n",
      "Iteration 10/100: Loss = 81.7147, Accuracy = 0.8500\n",
      "Iteration 11/100: Loss = 68.2823, Accuracy = 0.8500\n",
      "Iteration 12/100: Loss = 77.7878, Accuracy = 0.9000\n",
      "Iteration 13/100: Loss = 48.9131, Accuracy = 0.9250\n",
      "Iteration 14/100: Loss = 46.4415, Accuracy = 0.9500\n",
      "Iteration 15/100: Loss = 34.2775, Accuracy = 0.8974\n",
      "Iteration 16/100: Loss = 29.9672, Accuracy = 0.9500\n",
      "Iteration 17/100: Loss = 8.3507, Accuracy = 0.9750\n",
      "Iteration 18/100: Loss = 13.2752, Accuracy = 0.9250\n",
      "Iteration 19/100: Loss = 10.9477, Accuracy = 0.9250\n",
      "Iteration 20/100: Loss = 22.7900, Accuracy = 0.9750\n",
      "Iteration 21/100: Loss = 17.6793, Accuracy = 0.9750\n",
      "Iteration 22/100: Loss = 14.8135, Accuracy = 0.9250\n",
      "Iteration 23/100: Loss = 8.9155, Accuracy = 0.9250\n",
      "Iteration 24/100: Loss = 11.5688, Accuracy = 0.9750\n",
      "Iteration 25/100: Loss = 6.3602, Accuracy = 0.9250\n",
      "Iteration 26/100: Loss = 5.7039, Accuracy = 0.9500\n",
      "Iteration 27/100: Loss = 13.6156, Accuracy = 0.9000\n",
      "Iteration 28/100: Loss = 9.7063, Accuracy = 0.9500\n",
      "Iteration 29/100: Loss = 10.5031, Accuracy = 0.9500\n",
      "Iteration 30/100: Loss = 9.2578, Accuracy = 0.9500\n",
      "Iteration 31/100: Loss = 15.6690, Accuracy = 0.8571\n",
      "Iteration 32/100: Loss = 21.5637, Accuracy = 0.9250\n",
      "Iteration 33/100: Loss = 9.8426, Accuracy = 0.9250\n",
      "Iteration 34/100: Loss = 17.8224, Accuracy = 0.9250\n",
      "Iteration 35/100: Loss = 17.3500, Accuracy = 0.9500\n",
      "Iteration 36/100: Loss = 12.9932, Accuracy = 0.9750\n",
      "Iteration 37/100: Loss = 3.6055, Accuracy = 0.9500\n",
      "Iteration 38/100: Loss = 5.0739, Accuracy = 0.9750\n",
      "Iteration 39/100: Loss = 15.9200, Accuracy = 0.9750\n",
      "Iteration 40/100: Loss = 12.2953, Accuracy = 0.9750\n",
      "Iteration 41/100: Loss = 14.7071, Accuracy = 0.9250\n",
      "Iteration 42/100: Loss = 10.9336, Accuracy = 0.9250\n",
      "Iteration 43/100: Loss = 9.5870, Accuracy = 0.9750\n",
      "Iteration 44/100: Loss = 2.0005, Accuracy = 0.9750\n",
      "Iteration 45/100: Loss = 6.4786, Accuracy = 0.9500\n",
      "Iteration 46/100: Loss = 7.9809, Accuracy = 0.9500\n",
      "Iteration 47/100: Loss = 6.1246, Accuracy = 0.9250\n",
      "Iteration 48/100: Loss = 9.1070, Accuracy = 0.9750\n",
      "Iteration 49/100: Loss = 2.0000, Accuracy = 0.9750\n",
      "Iteration 50/100: Loss = 4.2518, Accuracy = 0.9750\n",
      "Iteration 51/100: Loss = 6.5834, Accuracy = 0.9750\n",
      "Iteration 52/100: Loss = 1.6440, Accuracy = 0.9750\n",
      "Iteration 53/100: Loss = 2.8676, Accuracy = 0.9500\n",
      "Iteration 54/100: Loss = 2.9539, Accuracy = 0.9750\n",
      "Iteration 55/100: Loss = 16.6804, Accuracy = 0.9744\n",
      "Iteration 56/100: Loss = 12.6630, Accuracy = 0.9750\n",
      "Iteration 57/100: Loss = 3.4127, Accuracy = 0.9750\n",
      "Iteration 58/100: Loss = 6.7192, Accuracy = 0.9750\n",
      "Iteration 59/100: Loss = 2.3127, Accuracy = 0.9750\n",
      "Iteration 60/100: Loss = 0.9687, Accuracy = 0.9750\n",
      "Iteration 61/100: Loss = 7.7325, Accuracy = 0.9500\n",
      "Iteration 62/100: Loss = 4.9446, Accuracy = 0.9500\n",
      "Iteration 63/100: Loss = 6.0189, Accuracy = 0.9750\n",
      "Iteration 64/100: Loss = 0.7725, Accuracy = 0.9750\n",
      "Iteration 65/100: Loss = 0.0000, Accuracy = 0.9750\n",
      "Iteration 66/100: Loss = 0.0000, Accuracy = 0.9750\n",
      "Iteration 67/100: Loss = 0.0000, Accuracy = 0.9750\n",
      "Iteration 68/100: Loss = 0.0000, Accuracy = 0.9750\n",
      "Iteration 69/100: Loss = 1.9968, Accuracy = 0.9250\n",
      "Iteration 70/100: Loss = 10.3502, Accuracy = 0.9750\n",
      "Iteration 71/100: Loss = 4.8123, Accuracy = 0.9500\n",
      "Iteration 72/100: Loss = 5.8442, Accuracy = 0.9750\n",
      "Iteration 73/100: Loss = 7.7923, Accuracy = 0.9750\n",
      "Iteration 74/100: Loss = 4.0617, Accuracy = 0.9750\n",
      "Iteration 75/100: Loss = 0.0309, Accuracy = 0.9750\n",
      "Iteration 76/100: Loss = 0.0125, Accuracy = 0.9750\n",
      "Iteration 77/100: Loss = 5.9998, Accuracy = 0.9750\n",
      "Iteration 78/100: Loss = 0.0000, Accuracy = 0.9750\n",
      "Iteration 79/100: Loss = 0.0000, Accuracy = 0.9750\n",
      "Iteration 80/100: Loss = 11.0290, Accuracy = 0.9250\n",
      "Iteration 81/100: Loss = 23.5290, Accuracy = 0.9250\n",
      "Iteration 82/100: Loss = 24.5583, Accuracy = 0.9000\n",
      "Iteration 83/100: Loss = 19.7477, Accuracy = 0.9500\n",
      "Iteration 84/100: Loss = 14.1515, Accuracy = 0.9744\n",
      "Iteration 85/100: Loss = 0.0971, Accuracy = 0.9500\n",
      "Iteration 86/100: Loss = 0.4780, Accuracy = 0.9744\n",
      "Iteration 87/100: Loss = 1.9995, Accuracy = 0.9744\n",
      "Iteration 88/100: Loss = 3.7096, Accuracy = 0.9744\n",
      "Iteration 89/100: Loss = 2.0048, Accuracy = 0.9750\n",
      "Iteration 90/100: Loss = 0.0000, Accuracy = 0.9750\n",
      "Iteration 91/100: Loss = 7.5528, Accuracy = 0.9750\n",
      "Iteration 92/100: Loss = 0.0000, Accuracy = 0.9750\n",
      "Iteration 93/100: Loss = 15.9669, Accuracy = 0.9500\n",
      "Iteration 94/100: Loss = 4.1426, Accuracy = 0.9231\n",
      "Iteration 95/100: Loss = 18.2304, Accuracy = 0.9250\n",
      "Iteration 96/100: Loss = 2.0007, Accuracy = 0.9744\n",
      "Iteration 97/100: Loss = 5.9749, Accuracy = 0.9250\n",
      "Iteration 98/100: Loss = 5.5730, Accuracy = 0.9750\n",
      "Iteration 99/100: Loss = 1.9817, Accuracy = 0.9500\n",
      "Iteration 100/100: Loss = 3.7476, Accuracy = 0.8750\n",
      "Model saved to: C:\\Users\\purus\\Downloads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x268919d3d10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_custom_ner_model(X_train_final, X_test_final, y_train_final, y_test_final, labels, iterations=100, model_output_dir=model_output_dir)\n",
    "\n",
    "#train_custom_ner_model(y_train_final, y_test_final, X_train_final, X_test_final, labels, iterations=100, model_output_dir='C:\\\\Users\\\\Anitha\\\\Downloads\\\\All Python Files\\\\DocManagement\\\\14Nov2023_DocAI_Spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b68024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your validation data is stored in X_val_final and y_val_final\n",
    "# Assuming your model is saved in the directory 'path/to/save/model'\n",
    "#model_output_dir = 'path/to/save/model'\n",
    "\n",
    "# Load the saved model\n",
    "loaded_nlp = spacy.load(model_output_dir)\n",
    "\n",
    "# Process each validation text and get predicted entities\n",
    "predicted_entities = []\n",
    "for i in range(len(X_val_final)):\n",
    "    text = str(X_val_final.iloc[i].item()) if isinstance(X_val_final.iloc[i], pd.Series) else str(X_val_final.iloc[i])\n",
    "    doc = loaded_nlp(text)\n",
    "    predicted_entities.extend([(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents])\n",
    "\n",
    "# Convert the predicted entities to the same format as y_val_final\n",
    "predicted_entities_df = pd.DataFrame(predicted_entities, columns=['start', 'end', 'label'])\n",
    "predicted_entities_df['label'] = predicted_entities_df['label'].astype(str)  # Ensure labels are strings\n",
    "\n",
    "# Convert y_val_final to the same format\n",
    "y_val_final_df = pd.DataFrame(\n",
    "    [(0, 0, str(item)) for item in y_val_final],  # Treat each integer as a separate entity\n",
    "    columns=['start', 'end', 'label']\n",
    ")\n",
    "\n",
    "# Create confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_val_final_df['label'], predicted_entities_df['label'])\n",
    "class_report = classification_report(y_val_final_df['label'], predicted_entities_df['label'])\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Assuming your validation data is stored in X_val_final and y_val_final\n",
    "# Assuming your model is saved in the directory 'path/to/save/model'\n",
    "#model_output_dir = 'path/to/save/model'\n",
    "\n",
    "# Load the saved model\n",
    "loaded_nlp = spacy.load(model_output_dir)\n",
    "\n",
    "# Process each validation text and get predicted entities\n",
    "predicted_entities = []\n",
    "for i in range(len(X_val_final)):\n",
    "    text = str(X_val_final.iloc[i].item()) if isinstance(X_val_final.iloc[i], pd.Series) else str(X_val_final.iloc[i])\n",
    "    doc = loaded_nlp(text)\n",
    "    predicted_entities.extend([(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents])\n",
    "\n",
    "# Convert the predicted entities to the same format as y_val_final\n",
    "predicted_entities_df = pd.DataFrame(predicted_entities, columns=['start', 'end', 'label'])\n",
    "predicted_entities_df['label'] = predicted_entities_df['label'].astype(str)  # Ensure labels are strings\n",
    "\n",
    "# Convert y_val_final to the same format\n",
    "y_val_final_df = pd.DataFrame(\n",
    "    [(0, 0, str(item)) for item in y_val_final],  # Treat each integer as a separate entity\n",
    "    columns=['start', 'end', 'label']\n",
    ")\n",
    "\n",
    "# Create confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_val_final_df['label'], predicted_entities_df['label'])\n",
    "class_report = classification_report(y_val_final_df['label'], predicted_entities_df['label'])\n",
    "\n",
    "# Plot confusion matrix using scikit-learn's ConfusionMatrixDisplay\n",
    "labels = sorted(y_val_final_df['label'].unique())  # assuming labels is defined\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\".0f\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e020bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
